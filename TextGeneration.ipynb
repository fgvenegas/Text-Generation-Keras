{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import GRU, Dense, Flatten, Conv1D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from numpy import array, argmax\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1511791155544320778\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_encode(text, alphabet):\n",
    "    values = array(list(alphabet))\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    text = list(text)\n",
    "    encoded_phrase = onehot_encoder.transform(label_encoder.transform(text).reshape(len(text), 1))\n",
    "    return encoded_phrase, label_encoder, onehot_encoder\n",
    "\n",
    "def encode_to_text(encode, label_encoder):\n",
    "    text = \"\"\n",
    "\n",
    "    for i in encode:\n",
    "        inverted = label_encoder.inverse_transform([argmax(i)])\n",
    "        text += inverted[0]\n",
    "  \n",
    "    return text\n",
    "\n",
    "def parse(text):\n",
    "    clean_text = re.sub('\\ +', ' ', text.replace('\\n', ' ').replace('\\r', ' '))\n",
    "    sigma      = set(text)\n",
    "  \n",
    "    return clean_text, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "INPUT_FILEPATH = 'chat.txt'\n",
    "WINDOW_SIZE    = 100\n",
    "\n",
    "X_train = None; y_train = None\n",
    "\n",
    "with open(INPUT_FILEPATH, 'r') as input_file:\n",
    "    text, sigma = parse(input_file.read())\n",
    "  \n",
    "    X_train = np.zeros((len(text) - WINDOW_SIZE + 1, WINDOW_SIZE - 1, len(sigma)))\n",
    "    y_train = np.zeros((len(text) - WINDOW_SIZE + 1, 1, len(sigma)))\n",
    "  \n",
    "    encoded_text, label_encoder, onehot_encoder = text_to_encode(text, sigma)\n",
    "  \n",
    "    i = 0\n",
    "    while i + WINDOW_SIZE < len(encoded_text) + 1:\n",
    "        X_train[i] = encoded_text[i:i + WINDOW_SIZE - 1]\n",
    "        y_train[i] = encoded_text[i + WINDOW_SIZE - 1]\n",
    "        i += 1\n",
    "\n",
    "# Ejemplos de correctitud\n",
    "# print(text_train_X[0], len(text_train_X[0]), text_train_y[0], len(text_train_y[0]))\n",
    "# print(text_train_X[-1], len(text_train_X[-1]), text_train_y[-1], len(text_train_y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((432, 99, 41), (432, 41))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no puedes levantarte tarde Hay que comer chorrillanas Lo sé lo sé Pondré mil alarmas Perfecto Ya di'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_to_text(X_train[111], label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 97, 150)           18600     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 97, 256)           312576    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 735,697\n",
      "Trainable params: 735,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=150, kernel_size=(3,), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(256, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(sigma), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 3.0598 - acc: 0.1898\n",
      "\n",
      "Epoch 00001: loss improved from 3.08341 to 3.05979, saving model to weights-improvement-01-3.0598.hdf5\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 3.0536 - acc: 0.1875\n",
      "\n",
      "Epoch 00002: loss improved from 3.05979 to 3.05362, saving model to weights-improvement-02-3.0536.hdf5\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 2.9989 - acc: 0.2014\n",
      "\n",
      "Epoch 00003: loss improved from 3.05362 to 2.99888, saving model to weights-improvement-03-2.9989.hdf5\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 7s 16ms/step - loss: 2.9756 - acc: 0.1921\n",
      "\n",
      "Epoch 00004: loss improved from 2.99888 to 2.97562, saving model to weights-improvement-04-2.9756.hdf5\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 7s 16ms/step - loss: 2.9747 - acc: 0.1968\n",
      "\n",
      "Epoch 00005: loss improved from 2.97562 to 2.97474, saving model to weights-improvement-05-2.9747.hdf5\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 6s 15ms/step - loss: 2.8790 - acc: 0.2315\n",
      "\n",
      "Epoch 00006: loss improved from 2.97474 to 2.87904, saving model to weights-improvement-06-2.8790.hdf5\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 2.8126 - acc: 0.2407\n",
      "\n",
      "Epoch 00007: loss improved from 2.87904 to 2.81263, saving model to weights-improvement-07-2.8126.hdf5\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.7440 - acc: 0.2731\n",
      "\n",
      "Epoch 00008: loss improved from 2.81263 to 2.74405, saving model to weights-improvement-08-2.7440.hdf5\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.6560 - acc: 0.2963\n",
      "\n",
      "Epoch 00009: loss improved from 2.74405 to 2.65605, saving model to weights-improvement-09-2.6560.hdf5\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.5472 - acc: 0.3194\n",
      "\n",
      "Epoch 00010: loss improved from 2.65605 to 2.54718, saving model to weights-improvement-10-2.5472.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119ac9908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: Create a real test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' levantarte tarde Hay que comer chorrillanas Lo sé lo sé Pondré mil alarmas Perfecto Ya dime Ya Jaj'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = X_train[120]\n",
    "print(\"Seed: \")\n",
    "encode_to_text(seed, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = encode_to_text(seed, label_encoder)\n",
    "\n",
    "for _ in range(200):\n",
    "    new_letter = model.predict(np.array([seed]))\n",
    "    new_text += encode_to_text(new_letter, label_encoder)   \n",
    "    seed = np.vstack((seed[1:], new_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " levantarte tarde Hay que comer chorrillanas Lo sé lo sé Pondré mil alarmas Perfecto Ya dime Ya Jajaaaaaaa                                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
